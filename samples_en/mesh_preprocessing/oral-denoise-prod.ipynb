{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "770950cc",
   "metadata": {},
   "source": [
    "# Mesh processing pipeline\n",
    "\n",
    "This workflow API takes oral scan mesh and returns everything you need for treatment planning.\n",
    "\n",
    "Please refer to https://www.chohotech.com/docs/cloud-en/#/workflow/oral-denoise-prod-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899e4510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import base64\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import trimesh\n",
    "import urllib\n",
    "import numpy as np\n",
    "\n",
    "def _create_colors():\n",
    "    # 20 high contrast colors\n",
    "    colors = [[230, 25, 75,255],[60, 180, 75,255],[255, 225, 25,255],\\\n",
    "            [0, 130, 200,255],[245, 130, 48,255],[145, 30, 180,255],[70, 240, 240,255],\\\n",
    "            [240, 50, 230,255],[210, 245, 60,255],[250, 190, 190,255],[0, 128, 128,255],\\\n",
    "            [230, 190, 255,255],[170, 110, 40,255],[255, 250, 200,255],[128, 0, 0,255],\\\n",
    "            [170, 255, 195,255],[128, 128, 0, 255]]\n",
    "    #np.random.shuffle(colors)\n",
    "    # gum color\n",
    "    colors = [[255,255,255,255]] + colors\n",
    "    return colors\n",
    "\n",
    "def colored_mesh(mesh, label):\n",
    "    COLORS = _create_colors()\n",
    "    mcopy = mesh.copy()\n",
    "    for i, l in enumerate(np.unique(label)):\n",
    "        mcopy.visual.face_colors[np.where(label == l)[0]] = COLORS[i % 18]\n",
    "    return mcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd41dcfa",
   "metadata": {},
   "source": [
    "## Define call rules\n",
    "Please modify the following code blocks based on the information you obtained from us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa010b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chohotech service request URL, sent with the API documentation.\n",
    "base_url = \"<service request URL>\"\n",
    "\n",
    "# Chohotech file service URL, sent with the API documentation.\n",
    "file_server_url = \"<service file server URL>\"\n",
    "\n",
    "# The authentication header must be passed in. Please keep the TOKEN confidential!!! If it is leaked, please contact us immediately to reset it. All tasks using this TOKEN will be charged to your account.\n",
    "zh_token = \"<your company's service Token, sent with the contact>\" # All API calls must be authenticated with the token.\n",
    "\n",
    "user_group = \"APIClient\" # User group, usually named APIClient.\n",
    "\n",
    "# Your company's user_id, sent with the API documentation.\n",
    "user_id = \"<your company's user_id>\"\n",
    "\n",
    "# If you have received creds.json, it will be read directly below.\n",
    "if os.path.exists('../../creds.json'):\n",
    "    creds = json.load(open('../../creds.json', 'r'))\n",
    "    base_url = creds['base_url']\n",
    "    file_server_url = creds['file_server_url']\n",
    "    zh_token = creds['zh_token']\n",
    "    user_id = creds['user_id']\n",
    "    print(\"loaded creds from creds.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a8ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_call = {\n",
    "  \"spec_group\": \"mesh-processing\",\n",
    "  \"spec_name\": \"oral-denoise-prod\",\n",
    "  \"spec_version\": \"1.0-snapshot\",\n",
    "  \"user_group\": user_group,\n",
    "  \"user_id\": user_id\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07efab22",
   "metadata": {},
   "source": [
    "### Define Callback URL\n",
    "\n",
    "Callback will send a POST request to the specified URL after the workflow is completed. The request content is a JSON object with 4 fields:\n",
    "\n",
    "1. workflow_id (str): the corresponding workflow_id\n",
    "2. metadata (dict): the metadata you passed when starting the workflow\n",
    "3. success (bool): whether the workflow succeeded (true for success)\n",
    "4. reason (str or null): If success is true, this item will be null. Otherwise, it will be a string representing the reason for failure.\n",
    "\n",
    "If you need a callback, please uncomment the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdd0ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_call['metadata'] = { # (optional) metadata can be added here, which will be attached to the callback information. Each item in the dictionary is limited to 128 characters\n",
    "#     \"case_id\": \"CH-123\",\n",
    "#     \"case_name\": \"ABCDE\"\n",
    "# }\n",
    "# json_call['notification'] =[ # (optional) callback URL can be added here\n",
    "#     {\"url\": \"https://www.baidu.com\"} # multiple callback URLs can be added here, each in the format {\"url\": \"xxx\"}\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798fcec2",
   "metadata": {},
   "source": [
    "## Define Input/Output Blocks\n",
    "\n",
    "The input block is defined by `input_data` in the JSON file. For 3D meshes, we support the following **input** file formats:\n",
    "\n",
    "```\n",
    "\"obj\"\n",
    "\"stl\"\n",
    "\"off\"\n",
    "\"ply\"\n",
    "\"glb\"\n",
    "\"zip\": There must be only one mesh file inside the zip, and its extension must be obj, stl, off, ply, or glb.\n",
    "\"tar.gz\": There must be only one mesh file inside the tar or tar.gz, and its extension must be obj, stl, off, ply, or glb.\n",
    "\"drc\"\n",
    "```\n",
    "\n",
    "and the following **output** file formats:\n",
    "```\n",
    "\"obj\"\n",
    "\"stl\"\n",
    "\"off\"\n",
    "\"ply\"\n",
    "\"glb\"\n",
    "\"drc\"\n",
    "```\n",
    "\n",
    "\n",
    "We **strongly recommend** using the `drc` file format for input/output to reduce network transmission time. The generation and reading of drc format files can be done using Google's Draco library: https://github.com/google/draco\n",
    "\n",
    "The table below shows the file size of the same 3D mesh in different file formats (point precision: 0.001mm):\n",
    "\n",
    "| File Format | File Size |\n",
    "| --- | --- |\n",
    "| stl | 16.7M |\n",
    "| obj | 13.5M |\n",
    "| off | 14.2M |\n",
    "| ply | 7.0M |\n",
    "| glb | 6.0M |\n",
    "| drc | 517.3K |\n",
    "\n",
    "\n",
    "For 3D meshes, input can be passed in two ways:\n",
    "\n",
    "1. Upload the 3D mesh file to our file service system first, then pass the file pointer to the request body and call the API.\n",
    "2. Directly pass the base64-encoded binary data in the request body.\n",
    "\n",
    "For 3D meshes, output can be specified in two ways:\n",
    "\n",
    "1. Return the file pointer as part of the API response, and users can download the specific binary file from our file system.\n",
    "2. Directly return the binary data in the form of base64 encoding in the API response.\n",
    "\n",
    "\n",
    "We **strongly recommend** using the first method for the following reasons:\n",
    "\n",
    "1. Base64 encoding will increase the bandwidth and increase network latency.\n",
    "2. To ensure API performance, Choho may reject API requests that are too large. Therefore, for large files, the second method will fail (HTTP CODE 413)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe0b57b",
   "metadata": {},
   "source": [
    "### Upload files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(file_name):\n",
    "    ext = file_name.split('.')[-1]\n",
    "    data = open('../../data/' + file_name, 'rb').read()\n",
    "    resp = requests.get(file_server_url + f\"/scratch/{user_group}/{user_id}/upload_url?\" +\n",
    "                        f\"postfix={ext}\", # Must specify postfix, i.e., the file extension\n",
    "                        headers={\"X-ZH-TOKEN\": zh_token}) # Get the signed upload URL\n",
    "    resp.raise_for_status()\n",
    "\n",
    "    upload_url = resp.text[1:-1] # Returns a single string JSON \"string\", can also use json.loads(resp.text)\n",
    "\n",
    "    resp = requests.put(upload_url, data)  # No auth header is needed for uploading to the cloud storage service\n",
    "\n",
    "    resp.raise_for_status()\n",
    "    path = \"/\".join(urllib.parse.urlparse(upload_url).path.lstrip(\"/\").split(\"/\")[3:])\n",
    "    urn = f\"urn:zhfile:o:s:{user_group}:{user_id}:{path}\"\n",
    "    return urn\n",
    "\n",
    "json_call[\"input_data\"] = {\n",
    "    \"mesh\": {\"type\":\"ply\", \"data\": upload_file('lower_jaw_scan.ply')},\n",
    "    \"jaw_type\": 'Lower'\n",
    "}\n",
    "\n",
    "json_call['output_config'] = {\n",
    "    \"mesh\": {\"type\": \"ply\"},\n",
    "    \"teeth_comp\": {\"type\": \"ply\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb3e44a",
   "metadata": {},
   "source": [
    "# Submit request\n",
    "\n",
    "Submit the request using the `/run` POST method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6da602",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"X-ZH-TOKEN\": zh_token\n",
    "}\n",
    "\n",
    "url = base_url + '/run'\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=json.dumps(json_call))\n",
    "response.raise_for_status()\n",
    "create_result = response.json()\n",
    "run_id = create_result['run_id']\n",
    "\n",
    "print(run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66bdd8d",
   "metadata": {},
   "source": [
    "# Wait for the request to complete\n",
    "\n",
    "Use the polling API to wait for the request to complete, the API URL is `/run/{run_id}`.\n",
    "\n",
    "**It is strongly recommended to use the callback method.** Refer to [Define Callback URL](#Define-Callback-URL), the callback method will send a callback message to the given URL at the end of the workflow, regardless of whether the workflow is successful or not, so you do not need to poll the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e2203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Polling the status\n",
    "url = base_url + f\"/run/{run_id}\"\n",
    "\n",
    "start_time = time.time()\n",
    "while time.time()-start_time < 300: # Maximum wait time: 5 minutes\n",
    "    time.sleep(0.3) # Polling interval\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    result = response.json()\n",
    "    if result['completed'] or result['failed']:\n",
    "        break\n",
    "\n",
    "if not result['completed']:\n",
    "    if result['failed']:\n",
    "        raise ValueError(\"API error, reason: \" + str(result['reason_public']))\n",
    "    raise TimeoutError(\"API timeout\")\n",
    "\n",
    "print(\"API execution time: {}s\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c85581",
   "metadata": {},
   "source": [
    "# Get the request result\n",
    "\n",
    "Use `/data/{run_id}` to get all output data of this workflow, use `/data/{run_id}/{key}` to get a specific item of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86e332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = base_url + f\"/data/{run_id}\"\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "result = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32f4027",
   "metadata": {},
   "outputs": [],
   "source": [
    "if result['mesh']['data'][:3] == \"urn\":\n",
    "    resp = requests.get(file_server_url + f\"/file/download?\" + urllib.parse.urlencode({\n",
    "                        \"urn\": result['mesh']['data']}),\n",
    "                        headers={\"X-ZH-TOKEN\": zh_token})\n",
    "    mesh_bytes = resp.content\n",
    "else:\n",
    "    mesh_bytes = base64.b64decode(result['mesh']['data'])\n",
    "result_mesh = trimesh.load(trimesh.util.wrap_as_stream(mesh_bytes), file_type=result['mesh']['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36263c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_comps={}\n",
    "for fdi, t_comp in result['teeth_comp'].items():\n",
    "    if t_comp['data'][:3] == \"urn\":\n",
    "        resp = requests.get(file_server_url + f\"/file/download?\" + urllib.parse.urlencode({\n",
    "                            \"urn\": t_comp['data']}),\n",
    "                            headers={\"X-ZH-TOKEN\": zh_token})\n",
    "        mesh_bytes = resp.content\n",
    "    else:\n",
    "        mesh_bytes = base64.b64decode(t_comp['data'])\n",
    "    t_comps[fdi] = trimesh.load(trimesh.util.wrap_as_stream(mesh_bytes), file_type=t_comp['type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2376edb8",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54722482",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('FDI list:', np.unique(result['seg_labels']))\n",
    "colored_mesh(result_mesh, result['seg_labels']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6fcd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform all teeth to their local coordinates\n",
    "def _get_vid_new_faces_by_fid(mesh, inds):\n",
    "    old_faces = mesh.faces[inds].reshape(-1)\n",
    "    vid = np.unique(old_faces)\n",
    "    vid_map = dict(zip(vid, np.arange(len(vid))))\n",
    "    faces = np.array([vid_map[x] for x in old_faces]).reshape(-1, 3)\n",
    "    return vid, faces\n",
    "\n",
    "def get_mesh_by_id(mesh, inds):\n",
    "    vid, faces = _get_vid_new_faces_by_fid(mesh, inds)\n",
    "    return trimesh.Trimesh(mesh.vertices[vid], faces)\n",
    "def split_tooth(mesh, label):\n",
    "    splitted = {}\n",
    "    unique_labels = np.unique(label)\n",
    "\n",
    "    for fdi in unique_labels:\n",
    "        if fdi == 0:\n",
    "            continue\n",
    "        idx = np.where(label == fdi)[0]\n",
    "        splitted[str(int(fdi))] = get_mesh_by_id(mesh, idx)\n",
    "    return splitted\n",
    "\n",
    "all_t = None\n",
    "for k, t in split_tooth(result_mesh, result['seg_labels']).items():\n",
    "    all_t += t.apply_transform(result['axis'][k])\n",
    "\n",
    "all_t.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534805c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize all teeth with adjacency faces reconstructed\n",
    "all_t_comps = sum(t_comps.values(), None)\n",
    "all_t_comps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9635da45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize all landmarks\n",
    "pts = []\n",
    "for m in result['landmarks'].values():\n",
    "    for k in m.values():\n",
    "        for g in k:\n",
    "            pts.append(g)\n",
    "\n",
    "_, i = all_t_comps.kdtree.query(pts, k=5)\n",
    "all_t_comps.visual.vertex_colors[i.ravel()] = [255, 0, 0, 255]\n",
    "all_t_comps.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "952042305c124a401f43d2f6cec8cbc4c7afc925a6a970f3fb140f7422802111"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
