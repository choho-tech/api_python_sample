{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cephalometric image analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import base64\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import urllib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define call rules\n",
    "Please modify the following code blocks based on the information you obtained from us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chohotech service request URL, sent with the API documentation.\n",
    "base_url = \"<service request URL>\"\n",
    "\n",
    "# Chohotech file service URL, sent with the API documentation.\n",
    "file_server_url = \"<service file server URL>\"\n",
    "\n",
    "# The authentication header must be passed in. Please keep the TOKEN confidential!!! If it is leaked, please contact us immediately to reset it. All tasks using this TOKEN will be charged to your account.\n",
    "zh_token = \"<your company's service Token, sent with the contact>\" # All API calls must be authenticated with the token.\n",
    "\n",
    "user_group = \"APIClient\" # User group, usually named APIClient.\n",
    "\n",
    "# Your company's user_id, sent with the API documentation.\n",
    "user_id = \"<your company's user_id>\"\n",
    "\n",
    "# If you have received creds.json, it will be read directly below.\n",
    "if os.path.exists('../../creds.json'):\n",
    "    creds = json.load(open('../../creds.json', 'r'))\n",
    "    base_url = creds['base_url']\n",
    "    file_server_url = creds['file_server_url']\n",
    "    zh_token = creds['zh_token']\n",
    "    user_id = creds['user_id']\n",
    "    print(\"loaded creds from creds.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_call = {\n",
    "    \"spec_version\": \"1.0-snapshot\",\n",
    "    \"spec_name\": \"ceph-analysis\",\n",
    "    \"spec_group\": \"ceph\",\n",
    "    \"user_group\": user_group,\n",
    "    \"user_id\": user_id\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Callback URL\n",
    "\n",
    "Callback will send a POST request to the specified URL after the workflow is completed. The request content is a JSON object with 4 fields:\n",
    "\n",
    "1. workflow_id (str): the corresponding workflow_id\n",
    "2. metadata (dict): the metadata you passed when starting the workflow\n",
    "3. success (bool): whether the workflow succeeded (true for success)\n",
    "4. reason (str or null): If success is true, this item will be null. Otherwise, it will be a string representing the reason for failure.\n",
    "\n",
    "If you need a callback, please uncomment the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_call['metadata'] = { # (optional) metadata can be added here, which will be attached to the callback information. Each item in the dictionary is limited to 128 characters\n",
    "#     \"case_id\": \"CH-123\",\n",
    "#     \"case_name\": \"ABCDE\"\n",
    "# }\n",
    "# json_call['notification'] =[ # (optional) callback URL can be added here\n",
    "#     {\"url\": \"https://www.baidu.com\"} # multiple callback URLs can be added here, each in the format {\"url\": \"xxx\"}\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Input/Output Blocks\n",
    "\n",
    "The input block is defined by `input_data` in the JSON file. For two-dimensional images, we support the following **input** file formats:\n",
    "\n",
    "```\n",
    "\"jpg\"\n",
    "\"jpeg\"\n",
    "\"png\"\n",
    "```\n",
    "\n",
    "For two-dimensional images, inputs can be passed in two ways:\n",
    "\n",
    "1. Upload the file to our file service system first, then write the file pointer into the JSON call string and call the API.\n",
    "2. Pass the base64-encoded binary data directly in the JSON call string.\n",
    "\n",
    "We **strongly recommend** using the first method for the following reasons:\n",
    "\n",
    "1. Base64 encoding will increase the data stream size and increase network latency.\n",
    "2. To ensure API performance, Choho will reject overly large API requests. Therefore, the second method will fail to call for large files (HTTP CODE 413)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(file_name):\n",
    "    ext = file_name.split('.')[-1]\n",
    "    data = open('../../data/' + file_name, 'rb').read()\n",
    "    resp = requests.get(file_server_url + f\"/scratch/{user_group}/{user_id}/upload_url?\" +\n",
    "                        f\"postfix={ext}\", # Must specify postfix, i.e., the file extension\n",
    "                        headers={\"X-ZH-TOKEN\": zh_token}) # Get the signed upload URL\n",
    "    resp.raise_for_status()\n",
    "\n",
    "    upload_url = resp.text[1:-1] # Returns a single string JSON \"string\", can also use json.loads(resp.text)\n",
    "\n",
    "    resp = requests.put(upload_url, data)  # No auth header is needed for uploading to the cloud storage service\n",
    "\n",
    "    resp.raise_for_status()\n",
    "    path = \"/\".join(urllib.parse.urlparse(upload_url).path.lstrip(\"/\").split(\"/\")[3:])\n",
    "    urn = f\"urn:zhfile:o:s:{user_group}:{user_id}:{path}\"\n",
    "    return urn\n",
    "\n",
    "json_call[\"input_data\"] = {\n",
    "    \"image\": upload_file('ceph.jpg')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit request\n",
    "\n",
    "Submit the request using the `/run` POST method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"X-ZH-TOKEN\": zh_token\n",
    "}\n",
    "\n",
    "url = base_url + '/run'\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=json.dumps(json_call))\n",
    "response.raise_for_status()\n",
    "create_result = response.json()\n",
    "run_id = create_result['run_id']\n",
    "\n",
    "print(run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wait for the request to complete\n",
    "\n",
    "Use the polling API to wait for the request to complete, the API URL is `/run/{run_id}`.\n",
    "\n",
    "**It is strongly recommended to use the callback method.** Refer to [Define Callback URL](#Define-Callback-URL), the callback method will send a callback message to the given URL at the end of the workflow, regardless of whether the workflow is successful or not, so you do not need to poll the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Polling the status\n",
    "url = base_url + f\"/run/{run_id}\"\n",
    "\n",
    "start_time = time.time()\n",
    "while time.time()-start_time < 180: # Maximum wait time: 3 minutes\n",
    "    time.sleep(0.3) # Polling interval\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    result = response.json()\n",
    "    if result['completed'] or result['failed']:\n",
    "        break\n",
    "\n",
    "if not result['completed']:\n",
    "    if result['failed']:\n",
    "        raise ValueError(\"API error, reason: \" + str(result['reason_public']))\n",
    "    raise TimeoutError(\"API timeout\")\n",
    "\n",
    "print(\"API execution time: {}s\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the request result\n",
    "\n",
    "Use `/data/{run_id}` to get all output data of this workflow, use `/data/{run_id}/{key}` to get a specific item of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = base_url + f\"/data/{run_id}\"\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "result = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "\n",
    "The following is the output result display of the lateral cephalometric analysis API. The code above this part is common for all APIs that take 2D images as input, while the following part is specific to the processing and display of lateral cephalometric analysis output.\n",
    "\n",
    "For specific output rules and fields of the lateral cephalometric analysis API, please refer to: https://www.chohotech.com/docs/cloud-en/#/module/ceph-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_teeth(img, pred):\n",
    "    kps = pred['kps']\n",
    "    all_pts = []\n",
    "    all_names = []\n",
    "    vis = img.copy()\n",
    "    for name, kp in kps.items():\n",
    "        x, y = int(kp[0]), int(kp[1])\n",
    "        cv2.circle(vis, (x, y), radius=3, color=(255, 255, 255), thickness=-1)\n",
    "        all_pts.append(kp)\n",
    "        all_names.append(name)\n",
    "    for kp in json.loads(pred['meta'])['lower_jaw_contour']:\n",
    "        x, y = int(kp[0]), int(kp[1])\n",
    "        cv2.circle(vis, (x, y), radius=3, color=(255, 0, 0), thickness=-1)\n",
    "\n",
    "    target_names = [\n",
    "        ['100800', '100040', '100802', '100803', '100041', '100805', '100300', '100807', '100808', '100054', '100810', '100053', '100812', '100042', '100814', '100055', '100043', '100045', '100818', '100050'],\n",
    "        ['100049', '100821', '100046', '100044', '100824', '100051', '100826', '100827', '100047', '100829', '100052', '100831', '100048', '100833', '100834', '100056', '100836'],\n",
    "        ['100019', '100018', '100839', '100840', '100020', '100022', '100021', '100844', '100845', '100303', '100027', '100017', '100026', '100850', '100851', '100016', '100025', '100015', '100855', '100856', '100857', '100858', '100859', '100860', '100861', '100862'],\n",
    "        ['100302', '100864', '100865', '100866', '100867', '100021'],\n",
    "        ['100008', '100870', '100013', '100872', '100873', '100874', '100008'],\n",
    "        ['100301', '100876', '100877', '100878', '100879', '100880', '100010', '100882', '100883', '100884', '100885', '100886', '100887', '100009', '100889', '100011', '100891', '100012'],\n",
    "        ['100893', '100894', '100003', '100896', '100897', '100898', '100899', '100003'],\n",
    "        ['100901', '100902', '100903', '100904', '100905', '100906', '100907', '100908', '100909', '100910', '100911', '100912', '100913', '100914', '100005', '100016', '100917', '100918', '100919', '100920', '100902', '100922'],\n",
    "        ['100004', '100924', '100925', '100926', '100004'],\n",
    "        ['100904', '100927', '100920', '100929'],\n",
    "        ['100930', '100007', '100932', '100933', '100934'],\n",
    "        ['100103', '100936', '100104', '100938', '100939', '100940', '100941', '100942', '100103'],\n",
    "        ['100220', '100221', '100222', '100223', '100224', '100225', '100226', '100227', '100228', '100229', '100230', '100231', '100232', '100233', '100234', '100235', '100220']\n",
    "    ]\n",
    "\n",
    "    for target_list in target_names:\n",
    "        for name in target_list[:-1]:\n",
    "            next_name = target_list[target_list.index(name) + 1]\n",
    "            if name in all_names and next_name in all_names:\n",
    "                idx1 = all_names.index(name)\n",
    "                idx2 = all_names.index(next_name)\n",
    "                x1, y1 = int(all_pts[idx1][0]), int(all_pts[idx1][1])\n",
    "                x2, y2 = int(all_pts[idx2][0]), int(all_pts[idx2][1])\n",
    "                cv2.line(vis, (x1, y1), (x2, y2), color=(0,255,0), thickness=1)\n",
    "    return vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../../data/ceph.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = vis_teeth(img, result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 14), dpi=80)\n",
    "plt.imshow(vis[:,:,::-1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "862987107cc000bc465df6f64a007a6c8d17c8cf7a32895d5460d35e9c5cb4f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
